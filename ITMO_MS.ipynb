{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTbww1/PSiFgo3ZMQ3q96m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grand00father/Itmo_MS/blob/main/ITMO_MS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Aj4ZOEnExw1A"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GROQ_KEY = userdata.get(\"GROK_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq faiss-cpu==1.13.2 langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOdQKuARzwdC",
        "outputId": "13e83a40-b2a6-4455-9eb4-010e629d2ce2",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting faiss-cpu==1.13.2\n",
            "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.7)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu==1.13.2) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu==1.13.2) (25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.2.7)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.6.5)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.14.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-1.0.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu, groq\n",
            "Successfully installed faiss-cpu-1.13.2 groq-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, List, Optional\n",
        "import json, re\n",
        "from langgraph.graph import StateGraph, END"
      ],
      "metadata": {
        "id": "vgBzSaIm_0po"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "client = Groq(api_key=GROQ_KEY)"
      ],
      "metadata": {
        "id": "55s21yvBFpyC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Interview_states(TypedDict):\n",
        "  name: Optional[str]\n",
        "  position: Optional[str]\n",
        "  grade: Optional[str]\n",
        "  experience: Optional[str]\n",
        "  history_user: List[str]\n",
        "  history_int_obs: List[str]\n",
        "  history_think: List[str]\n",
        "  answer: Optional[str]\n",
        "  done: bool\n",
        "  final_feedback : Optional[str]\n",
        "  turns: List[dict]\n",
        "  id: int"
      ],
      "metadata": {
        "id": "moNNp1Dn_3DH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intervier(state: Interview_states):\n",
        "  if state['id'] == -1:\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": (\n",
        "            '''Твой ответ должен содержать ТОЛЬКО формат JSON, который выглядит как:\\n\n",
        "            {\\n\n",
        "            \"question\":string\\n\n",
        "            }\\n\n",
        "            Ты IT специалист по имени Петр и ты начинаешь проводить техническое интервью у кандидата.\\n\n",
        "            Твоя задача:\\n\n",
        "            Поприветствовать кандидата и четко узнать данные о нем.\n",
        "            '''\n",
        "        )}\n",
        "        ]\n",
        "    response = client.chat.completions.create(\n",
        "              model='qwen/qwen3-32b',\n",
        "              messages=messages,\n",
        "              reasoning_effort=\"default\")\n",
        "\n",
        "    msg = response.choices[0].message.content.strip()\n",
        "    match = re.search(r\"\\{[\\s\\S]*\\}\", msg)\n",
        "    res = json.loads(match.group())\n",
        "    print(res['question'])\n",
        "    return {\n",
        "       'history_user' : state['history_user'] + [f\"Вопрос: {res['question']}\"]}\n",
        "\n",
        "  if state['done']:\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": (\n",
        "            '''Твой ответ должен содержать ТОЛЬКО формат JSON, который выглядит как:\\n\n",
        "            {\\n\n",
        "            \"think_about\":string,\\n\n",
        "            \"summary\":string\\n\n",
        "            }\\n\n",
        "            Ты IT специалист и это конец технического интервью.\\n\n",
        "            Твоя задача:\\n\n",
        "            Подумай, что ты думаешь о рекомендациях эксперта.\\n\n",
        "            Исходя из рекомендаций дать кандидату отзыв о его выступлении, который будет записан в summary и должен включать:\\n\n",
        "            Вердикт - Уровень кандидата (Junior / Middle / Senior) на основе предыдущих ответов (если кандидат не справлялся вообще, то поставь нулевой уровень);\\n\n",
        "            Cписок тем, затронутых в интервью - Темы, где кандидат дал точные ответы  и Темы, где были допущены ошибки или кандидат сказал «не знаю» (ты должен добавить правильный ответ на эти вопросы).\n",
        "            Анализ Soft Skills & Communication на основании того, насколько кандидат понятно излагает мысли, пытался ли кандидат выкрутиться/соврать или честно признал незнание;\\n\n",
        "            Персональный Roadmap - Список конкретных тем/технологий, которые нужно подтянуть (на основе выявленных пробелов).\n",
        "            '''\n",
        "        )},\n",
        "        {\"role\": \"user\", \"content\": f\"Рекомендации эксерта:{state[\"history_int_obs\"]}, Последний ответ:{state['answer']}\"}\n",
        "        ]\n",
        "    response = client.chat.completions.create(\n",
        "              model='qwen/qwen3-32b',\n",
        "              messages=messages,\n",
        "              reasoning_effort=\"default\")\n",
        "\n",
        "    msg = response.choices[0].message.content.strip()\n",
        "    match = re.search(r\"\\{[\\s\\S]*\\}\", msg)\n",
        "    res = json.loads(match.group())\n",
        "    print(f\"{res['summary']}\")\n",
        "    return {\n",
        "        'final_feedback' :  [f\"Резюме: {res['summary']}\"],\n",
        "        'history_user' : state['history_user'] + [f\"Резюме: {res['summary']}\"],\n",
        "        'history_think': state['history_think'] + [f\"{res['think_about']}\"],\n",
        "        \"turns\": state[\"turns\"] + [{\n",
        "              \"turn_id\": state[\"id\"],\n",
        "              \"agent_visible_message\": state[\"history_user\"][-2],\n",
        "              \"user_message\": state[\"answer\"],\n",
        "              \"internal_thoughts\": f\"[Observer]:<{state['history_int_obs'][-1]}> \\n [Interviewer]:<{res['think_about']}>\"}]}\n",
        "\n",
        "  messages = [\n",
        "        {\"role\": \"system\", \"content\": (\n",
        "            '''Твой ответ должен содержать ТОЛЬКО формат JSON, который выглядит как:\\n\n",
        "            {\\n\n",
        "            \"think_about\":string,\\n\n",
        "            \"question\":string\\n\n",
        "            }\\n\n",
        "            Ты IT специалист по имени Петр и проводишь техническое интервью на позицию''' + state['position'] + '''у кандидата по имени'''+ state['name'] + ''' с заявленным уровнем''' + state['grade']+ ''' и с опытом''' + state['experience'] +'''.\\n\n",
        "            Твоя задача:\\n\n",
        "            Подумай, что ты думаешь о рекомендациях эксперта.\\n\n",
        "            Вести с кандидатом диалог;\\n\n",
        "            Задавать кандидату вопросы, которые соответствуют его подготовке и уровню знаний;\\n\n",
        "            Также ориентируйся на рекомендации.\n",
        "            '''\n",
        "        )},\n",
        "        {\"role\": \"user\", \"content\": f\"Рекомендации эксерта:{state[\"history_int_obs\"]}, Последний ответ:{state['answer']}\"}\n",
        "    ]\n",
        "  response = client.chat.completions.create(\n",
        "            model='qwen/qwen3-32b',\n",
        "            messages=messages,\n",
        "            reasoning_effort=\"default\")\n",
        "\n",
        "  msg = response.choices[0].message.content.strip()\n",
        "  match = re.search(r\"\\{[\\s\\S]*\\}\", msg)\n",
        "  res = json.loads(match.group())\n",
        "  print(res['question'])\n",
        "  if state['id'] != 0:\n",
        "    return {'history_user': state['history_user'] + [f\"Вопрос: {res['question']}\"],\n",
        "            'history_think': state['history_think'] + [f\"{res['think_about']}\"],\n",
        "            \"turns\": state[\"turns\"] + [{\n",
        "              \"turn_id\": state[\"id\"],\n",
        "              \"agent_visible_message\": state[\"history_user\"][-2],\n",
        "              \"user_message\": state[\"answer\"],\n",
        "              \"internal_thoughts\": f\"[Observer]:<{state['history_int_obs'][-1]}> \\n [Interviewer]:<{res['think_about']}>\"}]}\n",
        "  return {'history_user': state['history_user'] + [f\"Вопрос: {res['question']}\"],\n",
        "            'history_think': state['history_think'] + [f\"{res['think_about']}\"]}\n",
        ""
      ],
      "metadata": {
        "id": "Z9NGva08Aafp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def observer(state: Interview_states):\n",
        "  if state['id'] == 0:\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": (\n",
        "            '''Твой ответ должен содержать ТОЛЬКО формат JSON, который выглядит как:\\n\n",
        "            {\\n\n",
        "            \"name\":string,\\n\n",
        "            \"position\":string,\\n\n",
        "            \"grade\":string,\\n\n",
        "            \"experience\":string,\\n\n",
        "            \"recomendation\":string\\n\n",
        "            }\\n\n",
        "            Ты IT эксперт, который помогает проводить техническое интервью.\\n\n",
        "            Твоя задача:\\n\n",
        "            Кандидат приставился, тебе необходимо выделить из его ответа соответствующие данные, которые указаны в json;\\n\n",
        "            Дай рекомендации интервьеру, по каким темам лучше дальше задать вопрос.\n",
        "            '''\n",
        "        )},\n",
        "        {\"role\": \"user\", \"content\": f\"История диалога:{state[\"history_user\"]}, Диалог с интервьером: {state['history_int_obs']}, Последний ответ:{state['answer']}\"}\n",
        "        ]\n",
        "    response = client.chat.completions.create(\n",
        "              model='qwen/qwen3-32b',\n",
        "              messages=messages,\n",
        "              reasoning_effort=\"default\")\n",
        "\n",
        "    msg = response.choices[0].message.content.strip()\n",
        "    match = re.search(r\"\\{[\\s\\S]*\\}\", msg)\n",
        "    res = json.loads(match.group())\n",
        "    return {\n",
        "       'name' : res['name'],\n",
        "       'position' : res['position'],\n",
        "       'grade' : res['grade'],\n",
        "       'experience' : res['experience'],\n",
        "       'history_int_obs': state['history_int_obs'] + [f\"Рекомендация: {res['recomendation']}\"]}\n",
        "\n",
        "  messages = [\n",
        "        {\"role\": \"system\", \"content\": (\n",
        "            '''Твой ответ должен содержать ТОЛЬКО формат JSON, который выглядит как:\\n\n",
        "            {\\n\n",
        "            \"recomendation\": string,\\n\n",
        "            \"done\": bool,\\n\n",
        "            \"summary\": string\\n\n",
        "            Ты IT эксперт, который помогает проводить техническое интервью на позицию''' + state['position'] + '''у кандидата по имени'''+ state['name'] + ''' с заявленным уровнем''' + state['grade']+ ''' и с опытом''' + state['experience'] +'''.\\n\n",
        "            Твоя задача:\\n\n",
        "            В начале посоветовать интервьеру поздороваться с кандидатом и узнать информацию о нем;\\n\n",
        "            Оценить ответ кандидата и решить, какой вопрос лучше задать дальше;\\n\n",
        "            В случае, если ты понимаешь, что кандидат не может справиться с вопросом, порекомендуй снизить сложность вопросов или, наоборот, повысить:\\n\n",
        "            Решать, достаточно ли информации;\\n\n",
        "            Если информации недостаточно — задать следующий логичный вопрос;\\n\n",
        "            Если информации достаточно — порекомендуй завершить интервью.\\n\n",
        "\n",
        "            }'''\n",
        "        )},\n",
        "        {\"role\": \"user\", \"content\": f\"История диалога:{state[\"history_user\"]}, Диалог с интервьером: {state['history_int_obs']}, Последний ответ:{state['answer']}\"}\n",
        "    ]\n",
        "  response = client.chat.completions.create(\n",
        "            model='qwen/qwen3-32b',\n",
        "            messages=messages,\n",
        "            reasoning_effort=\"default\")\n",
        "\n",
        "  msg = response.choices[0].message.content.strip()\n",
        "\n",
        "  match = re.search(r\"\\{[\\s\\S]*\\}\", msg)\n",
        "  res = json.loads(match.group())\n",
        "  if res['done']:\n",
        "    return {\n",
        "        'history_int_obs': state['history_int_obs'] + [f\"Резюме: {res['summary']}\"],\n",
        "\n",
        "        'done': True\n",
        "    }\n",
        "\n",
        "  return {\n",
        "      'history_int_obs': state['history_int_obs'] + [f\"Рекомендация: {res['recomendation']}\"],\n",
        "\n",
        "      'done': False\n",
        "  }"
      ],
      "metadata": {
        "id": "p8gXQg4tjXgN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_answer(state: Interview_states):\n",
        "  ans_user = input('>>> ')\n",
        "  return {\n",
        "      'answer': ans_user,\n",
        "      'id' : state['id'] + 1,\n",
        "      'history_user' : state[\"history_user\"] + [f\"Ответ: {state['answer']}\"]\n",
        "  }"
      ],
      "metadata": {
        "id": "9t-aqGp-yMup"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route(state: Interview_states):\n",
        "  return END if state['done'] == True else 'answer'"
      ],
      "metadata": {
        "id": "w8gC3PLMKgPh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(Interview_states)\n",
        "\n",
        "graph.add_node('intervier', intervier)\n",
        "graph.add_node('observer', observer)\n",
        "graph.add_node('answer', user_answer)\n",
        "\n",
        "graph.set_entry_point('intervier')\n",
        "\n",
        "graph.add_edge('observer', 'intervier')\n",
        "graph.add_edge('answer', 'observer')\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    'intervier',\n",
        "    route,\n",
        "    {\n",
        "        \"answer\": \"answer\",\n",
        "        END: END\n",
        "    }\n",
        ")\n",
        "\n",
        "app = graph.compile()"
      ],
      "metadata": {
        "id": "HXewY8d3JQma"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = {\n",
        "    'name':None,\n",
        "    'position': None,\n",
        "    'grade': None,\n",
        "    'experience': None,\n",
        "    'history_user': [],\n",
        "    'history_int_obs': [],\n",
        "    'history_think' : [],\n",
        "    'answer': None,\n",
        "    'done': False,\n",
        "    'turns': [],\n",
        "    'id': -1,\n",
        "    'final_feedback' : None\n",
        "}\n",
        "\n",
        "state = app.invoke(state)\n",
        "logs = {\n",
        "    \"participant_name\":state['name'],\n",
        "    'turns': state['turns'],\n",
        "    'final_feedback':state['final_feedback']\n",
        "}\n",
        "with open(\"interview_log.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(logs, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu9k1QYPMGUy",
        "outputId": "fc506371-ba17-40b8-acbe-291879b1e766"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Здравствуйте, меня зовут Петр. Рад приветствовать вас на техническом интервью. Пожалуйста, представьтесь: как зовут, сколько опыта работы в IT и на каком уровне говорите по-английски (включая IT-английский)?\n",
            ">>> Привет, меня зовут Святослав. Я хочу попасть на вакансию стажер ML инженер.с\n",
            "Расскажите, пожалуйста, чем отличаются алгоритмы супервизированного машинного обучения от несупервизированного. Приведите по одному примеру задачи и алгоритма для каждой категории.\n",
            ">>> 1 - когда у нас есть известный таргет и мы обучаем модель на нем (логистическая регрессия). 2 - когда модель учится относить обьекты к таргету не зная его (метод k близжайших соседей)\n",
            "Какие метрики вы используете для оценки качества моделей в задачах классификации и регрессии? Приведите пример выбора метрики под конкретную задачу.\n",
            ">>> recall, precision, auc-roc . регрессия - mse,mae, усредненный mae по таргету. бинарная классификации больных - recall\n",
            "В вашем примере с задачей бинарной классификации больных вы выбрали recall. Почему именно recall, а не precision? Каковы риски этого выбора и как вы бы их минимизировали в практической реализации?\n",
            ">>> потому что recall более чувствительный к ошибке 2 рода. лучше использовать f1 меру\n",
            "Вердикт: Junior\n",
            "\n",
            "Затронутые темы:\n",
            "- Основные метрики (recall, precision, F1) — частично корректный ответ;\n",
            "- Компромиссы выбора метрик (recall vs precision) — неполный ответ (не приведён пример задачи);\n",
            "- Понимание ошибок II рода — частично упомянуто.\n",
            "\n",
            "Soft Skills: Ответы сжаты, примеры отсутствуют. Кандидат не смог выстроить логическую цепочку рассуждений, но честно не признал незнание.\n",
            "\n",
            "Персональный Roadmap: Глубже изучить примеры задач классификации с компромиссами в метриках (например, задачи безопасности или медицины), формализовать подход к выбору метрик. Уточнить термины (ошибки I/II рода, F1-мера как гармоническое среднее). Практиковать английский технический словарь.\n"
          ]
        }
      ]
    }
  ]
}